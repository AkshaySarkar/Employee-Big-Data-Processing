{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBzAi2lHUFX5LULQf+vLpv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkshaySarkar/Employee-Big-Data-Processing/blob/main/BigData_Processing2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E02NipQYOkO",
        "outputId": "ea543739-42a0-4317-b0a6-6371856dcc2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark, wget\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=e1fb854560339142307a42db9f4efdc4391496b5ec90ffb5e49fdd7c541ed8b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=b5b8312c0d59bc84eab0ba7588b8d4b81e6b55165476f4d9e249c1142416da6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built pyspark wget\n",
            "Installing collected packages: wget, findspark, pyspark\n",
            "Successfully installed findspark-2.0.1 pyspark-3.5.1 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "# Installing required packages\n",
        "\n",
        "!pip install pyspark  findspark wget\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "HYE28o4QpsXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PySpark is the Spark API for Python. In this lab, we use PySpark to initialize the SparkContext.\n",
        "\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "nnTpzHCKpsdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a SparkContext object\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# Creating a SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark DataFrames basic example\") \\\n",
        "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "z-BITVDkpsrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the CSV data first into a local `employees.csv` file\n",
        "import wget\n",
        "wget.download(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/data/employees.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y68JMyK9psvj",
        "outputId": "fd55192b-b8c8-45cb-e5e8-1c7d85ed3623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'employees.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading data from the \"emp\" CSV file and import it into a DataFrame variable named \"employees_df\"\n",
        "df = spark.read.csv(\"employees.csv\", inferSchema=True)"
      ],
      "metadata": {
        "id": "EWM5SFFhpszx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a Schema for the input data and read the file using the user-defined Schema\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "schema = StructType([\n",
        "    StructField(\"Emp_No\", IntegerType(), True),\n",
        "    StructField(\"Emp_Name\", StringType(), True),\n",
        "    StructField(\"Salary\", IntegerType(), True),\n",
        "     StructField(\"Age\", IntegerType(), True),\n",
        "     StructField(\"Department\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Reading the file with the user-defined schema\n",
        "df = spark.read.csv(\"employees.csv\", schema=schema)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXh2Msbdps29",
        "outputId": "3e5713cd-13e8-4fe2-e2a3-3dc35c43ff17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+------+----+----------+\n",
            "|Emp_No| Emp_Name|Salary| Age|Department|\n",
            "+------+---------+------+----+----------+\n",
            "|  NULL| Emp_Name|  NULL|NULL|Department|\n",
            "|   198|   Donald|  2600|  29|        IT|\n",
            "|   199|  Douglas|  2600|  34|     Sales|\n",
            "|   200| Jennifer|  4400|  36| Marketing|\n",
            "|   201|  Michael| 13000|  32|        IT|\n",
            "|   202|      Pat|  6000|  39|        HR|\n",
            "|   203|    Susan|  6500|  36| Marketing|\n",
            "|   204|  Hermann| 10000|  29|   Finance|\n",
            "|   205|  Shelley| 12008|  33|   Finance|\n",
            "|   206|  William|  8300|  37|        IT|\n",
            "|   100|   Steven| 24000|  39|        IT|\n",
            "|   101|    Neena| 17000|  27|     Sales|\n",
            "|   102|      Lex| 17000|  37| Marketing|\n",
            "|   103|Alexander|  9000|  39| Marketing|\n",
            "|   104|    Bruce|  6000|  38|        IT|\n",
            "|   105|    David|  4800|  39|        IT|\n",
            "|   106|    Valli|  4800|  38|     Sales|\n",
            "|   107|    Diana|  4200|  35|     Sales|\n",
            "|   108|    Nancy| 12008|  28|     Sales|\n",
            "|   109|   Daniel|  9000|  35|        HR|\n",
            "+------+---------+------+----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying all columns of the DataFrame, along with their respective data types\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1luLfXOptN7",
        "outputId": "44040c23-e6fc-4e27-b3d3-e96bd57365f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Emp_No: integer (nullable = true)\n",
            " |-- Emp_Name: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a temporary view named \"employees\" for the DataFrame\n",
        "df.createOrReplaceTempView(\"employees\")"
      ],
      "metadata": {
        "id": "ZMRAjpHlptQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL query to fetch solely the records from the View where the age exceeds 30\n",
        "result = spark.sql(\"SELECT * FROM employees WHERE Age > 30\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0QU3yVGptTk",
        "outputId": "40dfdea9-1371-4d3e-f3ff-5d93dab9de91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+---+----------+\n",
            "|Emp_No|   Emp_Name|Salary|Age|Department|\n",
            "+------+-----------+------+---+----------+\n",
            "|   199|    Douglas|  2600| 34|     Sales|\n",
            "|   200|   Jennifer|  4400| 36| Marketing|\n",
            "|   201|    Michael| 13000| 32|        IT|\n",
            "|   202|        Pat|  6000| 39|        HR|\n",
            "|   203|      Susan|  6500| 36| Marketing|\n",
            "|   205|    Shelley| 12008| 33|   Finance|\n",
            "|   206|    William|  8300| 37|        IT|\n",
            "|   100|     Steven| 24000| 39|        IT|\n",
            "|   102|        Lex| 17000| 37| Marketing|\n",
            "|   103|  Alexander|  9000| 39| Marketing|\n",
            "|   104|      Bruce|  6000| 38|        IT|\n",
            "|   105|      David|  4800| 39|        IT|\n",
            "|   106|      Valli|  4800| 38|     Sales|\n",
            "|   107|      Diana|  4200| 35|     Sales|\n",
            "|   109|     Daniel|  9000| 35|        HR|\n",
            "|   110|       John|  8200| 31| Marketing|\n",
            "|   111|     Ismael|  7700| 32|        IT|\n",
            "|   112|Jose Manuel|  7800| 34|        HR|\n",
            "|   113|       Luis|  6900| 34|     Sales|\n",
            "|   116|     Shelli|  2900| 37|   Finance|\n",
            "+------+-----------+------+---+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the average salary of employees grouped by department\n",
        "result = spark.sql(\"SELECT Department, AVG(Salary) AS avg_salary FROM employees GROUP BY Department\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY08vepUptWm",
        "outputId": "af591794-1060-4791-f1ec-b61310e27d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+\n",
            "|Department|       avg_salary|\n",
            "+----------+-----------------+\n",
            "|     Sales|5492.923076923077|\n",
            "|        HR|           5837.5|\n",
            "|Department|             NULL|\n",
            "|   Finance|           5730.8|\n",
            "| Marketing|6633.333333333333|\n",
            "|        IT|           7400.0|\n",
            "+----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying a filter to select records where the department is 'IT'\n",
        "result = spark.sql(\"SELECT * FROM employees WHERE Department = 'IT'\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1d-n-wyptZx",
        "outputId": "9f4f5dc6-8f34-4790-e8d2-5dc45296c6a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+---+----------+\n",
            "|Emp_No|Emp_Name|Salary|Age|Department|\n",
            "+------+--------+------+---+----------+\n",
            "|   198|  Donald|  2600| 29|        IT|\n",
            "|   201| Michael| 13000| 32|        IT|\n",
            "|   206| William|  8300| 37|        IT|\n",
            "|   100|  Steven| 24000| 39|        IT|\n",
            "|   104|   Bruce|  6000| 38|        IT|\n",
            "|   105|   David|  4800| 39|        IT|\n",
            "|   111|  Ismael|  7700| 32|        IT|\n",
            "|   129|   Laura|  3300| 38|        IT|\n",
            "|   132|      TJ|  2100| 34|        IT|\n",
            "|   136|   Hazel|  2200| 29|        IT|\n",
            "+------+--------+------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Adding a new column \"SalaryAfterBonus\" with 10% bonus added to the original salary\n",
        "df = df.withColumn(\"SalaryAfterBonus\", col(\"Salary\") * 1.1)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4xFq7uhwzH5",
        "outputId": "9a748c39-bad9-4cbd-a4f8-cd93740ff277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+------+----+----------+------------------+\n",
            "|Emp_No| Emp_Name|Salary| Age|Department|  SalaryAfterBonus|\n",
            "+------+---------+------+----+----------+------------------+\n",
            "|  NULL| Emp_Name|  NULL|NULL|Department|              NULL|\n",
            "|   198|   Donald|  2600|  29|        IT|2860.0000000000005|\n",
            "|   199|  Douglas|  2600|  34|     Sales|2860.0000000000005|\n",
            "|   200| Jennifer|  4400|  36| Marketing|            4840.0|\n",
            "|   201|  Michael| 13000|  32|        IT|14300.000000000002|\n",
            "|   202|      Pat|  6000|  39|        HR| 6600.000000000001|\n",
            "|   203|    Susan|  6500|  36| Marketing| 7150.000000000001|\n",
            "|   204|  Hermann| 10000|  29|   Finance|           11000.0|\n",
            "|   205|  Shelley| 12008|  33|   Finance|13208.800000000001|\n",
            "|   206|  William|  8300|  37|        IT|            9130.0|\n",
            "|   100|   Steven| 24000|  39|        IT|26400.000000000004|\n",
            "|   101|    Neena| 17000|  27|     Sales|           18700.0|\n",
            "|   102|      Lex| 17000|  37| Marketing|           18700.0|\n",
            "|   103|Alexander|  9000|  39| Marketing|            9900.0|\n",
            "|   104|    Bruce|  6000|  38|        IT| 6600.000000000001|\n",
            "|   105|    David|  4800|  39|        IT|            5280.0|\n",
            "|   106|    Valli|  4800|  38|     Sales|            5280.0|\n",
            "|   107|    Diana|  4200|  35|     Sales|            4620.0|\n",
            "|   108|    Nancy| 12008|  28|     Sales|13208.800000000001|\n",
            "|   109|   Daniel|  9000|  35|        HR|            9900.0|\n",
            "+------+---------+------+----+----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Grouping data by age and calculate the maximum salary for each age group\n",
        "result = df.groupBy(\"Age\").agg(F.max(\"Salary\").alias(\"max_salary\"))\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLuGJ0Fuw3YG",
        "outputId": "3bd5fdeb-66e4-4cc0-94f5-7af7ec065137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+\n",
            "| Age|max_salary|\n",
            "+----+----------+\n",
            "|  31|      8200|\n",
            "|  34|      7800|\n",
            "|  28|     12008|\n",
            "|  27|     17000|\n",
            "|  26|      3600|\n",
            "|NULL|      NULL|\n",
            "|  37|     17000|\n",
            "|  35|      9000|\n",
            "|  39|     24000|\n",
            "|  38|      6000|\n",
            "|  29|     10000|\n",
            "|  32|     13000|\n",
            "|  33|     12008|\n",
            "|  30|      8000|\n",
            "|  36|      7900|\n",
            "+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the DataFrame with itself based on the \"Emp_No\" column\n",
        "result = df.alias(\"df1\").join(df.alias(\"df2\"), \"Emp_No\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4AxKizUxO0l",
        "outputId": "341a8527-980e-4c66-cfc0-a3b4490d45aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+------+---+----------+------------------+---------+------+---+----------+------------------+\n",
            "|Emp_No| Emp_Name|Salary|Age|Department|  SalaryAfterBonus| Emp_Name|Salary|Age|Department|  SalaryAfterBonus|\n",
            "+------+---------+------+---+----------+------------------+---------+------+---+----------+------------------+\n",
            "|   198|   Donald|  2600| 29|        IT|2860.0000000000005|   Donald|  2600| 29|        IT|2860.0000000000005|\n",
            "|   199|  Douglas|  2600| 34|     Sales|2860.0000000000005|  Douglas|  2600| 34|     Sales|2860.0000000000005|\n",
            "|   200| Jennifer|  4400| 36| Marketing|            4840.0| Jennifer|  4400| 36| Marketing|            4840.0|\n",
            "|   201|  Michael| 13000| 32|        IT|14300.000000000002|  Michael| 13000| 32|        IT|14300.000000000002|\n",
            "|   202|      Pat|  6000| 39|        HR| 6600.000000000001|      Pat|  6000| 39|        HR| 6600.000000000001|\n",
            "|   203|    Susan|  6500| 36| Marketing| 7150.000000000001|    Susan|  6500| 36| Marketing| 7150.000000000001|\n",
            "|   204|  Hermann| 10000| 29|   Finance|           11000.0|  Hermann| 10000| 29|   Finance|           11000.0|\n",
            "|   205|  Shelley| 12008| 33|   Finance|13208.800000000001|  Shelley| 12008| 33|   Finance|13208.800000000001|\n",
            "|   206|  William|  8300| 37|        IT|            9130.0|  William|  8300| 37|        IT|            9130.0|\n",
            "|   100|   Steven| 24000| 39|        IT|26400.000000000004|   Steven| 24000| 39|        IT|26400.000000000004|\n",
            "|   101|    Neena| 17000| 27|     Sales|           18700.0|    Neena| 17000| 27|     Sales|           18700.0|\n",
            "|   102|      Lex| 17000| 37| Marketing|           18700.0|      Lex| 17000| 37| Marketing|           18700.0|\n",
            "|   103|Alexander|  9000| 39| Marketing|            9900.0|Alexander|  9000| 39| Marketing|            9900.0|\n",
            "|   104|    Bruce|  6000| 38|        IT| 6600.000000000001|    Bruce|  6000| 38|        IT| 6600.000000000001|\n",
            "|   105|    David|  4800| 39|        IT|            5280.0|    David|  4800| 39|        IT|            5280.0|\n",
            "|   106|    Valli|  4800| 38|     Sales|            5280.0|    Valli|  4800| 38|     Sales|            5280.0|\n",
            "|   107|    Diana|  4200| 35|     Sales|            4620.0|    Diana|  4200| 35|     Sales|            4620.0|\n",
            "|   108|    Nancy| 12008| 28|     Sales|13208.800000000001|    Nancy| 12008| 28|     Sales|13208.800000000001|\n",
            "|   109|   Daniel|  9000| 35|        HR|            9900.0|   Daniel|  9000| 35|        HR|            9900.0|\n",
            "|   110|     John|  8200| 31| Marketing|            9020.0|     John|  8200| 31| Marketing|            9020.0|\n",
            "+------+---------+------+---+----------+------------------+---------+------+---+----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the average age of employees\n",
        "from pyspark.sql.functions import avg\n",
        "average_age = df.agg(avg(\"Age\").alias(\"average_age\"))\n",
        "\n",
        "average_age.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJbhoGJgxW7c",
        "outputId": "66fb80cd-f120-40a6-d5cf-e749072dfc7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|average_age|\n",
            "+-----------+\n",
            "|      33.56|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the total salary for each department\n",
        "from pyspark.sql.functions import sum\n",
        "total_salary_per_department = df.groupBy(\"department\").agg(sum(\"salary\").alias(\"total_salary\"))\n",
        "\n",
        "total_salary_per_department.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAPgB_5xxdbQ",
        "outputId": "347a3c11-7a61-4f49-cee2-a0b4ef1e9be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+\n",
            "|department|total_salary|\n",
            "+----------+------------+\n",
            "|     Sales|       71408|\n",
            "|        HR|       46700|\n",
            "|Department|        NULL|\n",
            "|   Finance|       57308|\n",
            "| Marketing|       59700|\n",
            "|        IT|       74000|\n",
            "+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting the DataFrame by age in ascending order and then by salary in descending order\n",
        "from pyspark.sql import functions as F\n",
        "sorted_df = df.orderBy(F.asc(\"Age\"),F.desc(\"Salary\"))\n",
        "\n",
        "sorted_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8ShPw4uxoX2",
        "outputId": "019726b7-12b7-422a-afb1-8f1d3f873e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+------+----+----------+------------------+\n",
            "|Emp_No| Emp_Name|Salary| Age|Department|  SalaryAfterBonus|\n",
            "+------+---------+------+----+----------+------------------+\n",
            "|  NULL| Emp_Name|  NULL|NULL|Department|              NULL|\n",
            "|   137|   Renske|  3600|  26| Marketing|3960.0000000000005|\n",
            "|   101|    Neena| 17000|  27|     Sales|           18700.0|\n",
            "|   114|      Den| 11000|  27|   Finance|12100.000000000002|\n",
            "|   108|    Nancy| 12008|  28|     Sales|13208.800000000001|\n",
            "|   130|    Mozhe|  2800|  28| Marketing|3080.0000000000005|\n",
            "|   126|    Irene|  2700|  28|        HR|2970.0000000000005|\n",
            "|   204|  Hermann| 10000|  29|   Finance|           11000.0|\n",
            "|   115|Alexander|  3100|  29|   Finance|3410.0000000000005|\n",
            "|   134|  Michael|  2900|  29|     Sales|3190.0000000000005|\n",
            "|   198|   Donald|  2600|  29|        IT|2860.0000000000005|\n",
            "|   140|   Joshua|  2500|  29|   Finance|            2750.0|\n",
            "|   136|    Hazel|  2200|  29|        IT|            2420.0|\n",
            "|   120|  Matthew|  8000|  30|        HR|            8800.0|\n",
            "|   110|     John|  8200|  31| Marketing|            9020.0|\n",
            "|   127|    James|  2400|  31|        HR|            2640.0|\n",
            "|   201|  Michael| 13000|  32|        IT|14300.000000000002|\n",
            "|   111|   Ismael|  7700|  32|        IT|            8470.0|\n",
            "|   119|    Karen|  2500|  32|   Finance|            2750.0|\n",
            "|   205|  Shelley| 12008|  33|   Finance|13208.800000000001|\n",
            "+------+---------+------+----+----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count\n",
        "\n",
        "employee_count_per_department = df.groupBy(\"Department\").count()\n",
        "\n",
        "employee_count_per_department.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBW3lifVxxGz",
        "outputId": "3c1e86e1-c21f-49ad-bf71-a7ffb3779a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|Department|count|\n",
            "+----------+-----+\n",
            "|     Sales|   13|\n",
            "|        HR|    8|\n",
            "|Department|    1|\n",
            "|   Finance|   10|\n",
            "| Marketing|    9|\n",
            "|        IT|   10|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying a filter to select records where the employee's name contains the letter 'o'\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "filtered_df = df.filter(col(\"Emp_Name\").like(\"%o%\"))\n",
        "\n",
        "filtered_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFwvuR5ax3Gb",
        "outputId": "0ed448af-c84d-448e-fb32-73f0651672ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+---+----------+------------------+\n",
            "|Emp_No|   Emp_Name|Salary|Age|Department|  SalaryAfterBonus|\n",
            "+------+-----------+------+---+----------+------------------+\n",
            "|   198|     Donald|  2600| 29|        IT|2860.0000000000005|\n",
            "|   199|    Douglas|  2600| 34|     Sales|2860.0000000000005|\n",
            "|   110|       John|  8200| 31| Marketing|            9020.0|\n",
            "|   112|Jose Manuel|  7800| 34|        HR|            8580.0|\n",
            "|   130|      Mozhe|  2800| 28| Marketing|3080.0000000000005|\n",
            "|   133|      Jason|  3300| 38|     Sales|3630.0000000000005|\n",
            "|   139|       John|  2700| 36|     Sales|2970.0000000000005|\n",
            "|   140|     Joshua|  2500| 29|   Finance|            2750.0|\n",
            "+------+-----------+------+---+----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SsY0CpbLdc0r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}